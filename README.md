# LLM-reasoning-pop-quiz

[![License](https://img.shields.io/badge/License-Apache_2.0-green.svg)](https://github.com/daniel-furman/Polyglot-or-Not/blob/main/LICENSE) 
[![Python 3.9+](https://img.shields.io/badge/python-3.9+-blue.svg)](https://www.python.org/downloads/release/python-390/) 
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black) 

Do open-source LLMs have the reasoning prowess of ChatGPT?

---

### TO DOs

* add a github repo for these where the modeling pipeline function gets read in from a script
* add two more examples per type, perhaps referencing the papers for the other examples
* add direct caching to csv in notebook, enable running chunks separately, caching
* model results 
* include gpt-3.5 api
* include dolly-v2-12b
* include llama-33b as a flex?
* include falcon-chat / falcon base model for comparison!
* read in a yaml file with prompts to run!
